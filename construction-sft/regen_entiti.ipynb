{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = ''\n",
    "# Should be the output of the first_pass_gen\n",
    "work_on_data = 'data_with_reasonings_0.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict, Any\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import json\n",
    "import uuid\n",
    "from langchain_core.documents import Document\n",
    "from time import time\n",
    "import chromadb\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import Field, BaseModel\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "import loguru\n",
    "import pickle\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote, quote_plus, urlparse, parse_qs, urlunparse, urlencode\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalRequest(BaseModel):\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=\"The process of how you arrived on the following queries you are going to make based on the input. Reasoning should be concise and contain only important points.\"\n",
    "    )\n",
    "    queries: list[str] = Field(\n",
    "        description=\"The queries you want to make. Each should be a question.\"\n",
    "    )\n",
    "\n",
    "class RefinedResult(BaseModel):\n",
    "\n",
    "    refined_result: str = Field(\n",
    "        description=\"The refined result of the given message. Should be in no more than 2 to 3 sentences. Should contain no more content than what's related to the query.\"\n",
    "    )\n",
    "\n",
    "class ReasoningCheck(BaseModel):\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=\"The reason why you assert that you can deduce the answer of the professional doctor from the given information, or why you cannot deduce it. Reasoning should be concise and contain only important points.\"\n",
    "    )\n",
    "    deducible: bool = Field(description=\"Whether you can deduce the answer of the professional doctor from the given information.\")\n",
    "\n",
    "class Response(BaseModel):\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=\"The reason why you ask the user for more information or respond to them. Reasoning should be concise and contain only important points.\"\n",
    "    )\n",
    "    is_asking: bool = Field(\n",
    "        description=\"Wehther your sentence asks the user for more information or tell them something. If this is true, this response will be marked as ask, or else it will be marked as tell.\"\n",
    "    )\n",
    "    entities: list[str] = Field(\n",
    "        description=\"The medical entities related to this conversation. Only the important ones should be included.\"\n",
    "    )\n",
    "    text: str = Field(\n",
    "        description=\"The text sent to the patient.\"\n",
    "    )\n",
    "\n",
    "class Conversation(TypedDict):\n",
    "    \n",
    "    patient: str\n",
    "    doctor: str\n",
    "\n",
    "class RetrievalItem(TypedDict):\n",
    "    \n",
    "    query: str\n",
    "    refined_result: str\n",
    "\n",
    "class StructuredOutputWithRaw(TypedDict):\n",
    "    \n",
    "    raw: AIMessage\n",
    "    parsed: Any\n",
    "    parsing_error: Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_llm = ChatOllama(model=\"qwen2.5:32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AskingPart(BaseModel):\n",
    "\n",
    "    asking: str = Field(\n",
    "        description=\"The part of the sentence that the teacher asked.\"\n",
    "    )\n",
    "prompt_ask = \"重复句子\\n{}\\n的问句部分，以 AskingPart 的方式给出。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"在医患对话场景中，医生通常会提问以下几种对象。\n",
    "\n",
    "- 疾病：即具体的疾病名称。\n",
    "- 临床表现：即患者的症状，例如：头疼。\n",
    "- 药物：即具体的药品名称，例如：阿司匹林。\n",
    "- 手术：即具体的手术名称，例如：阑尾切除，心脏搭桥。\n",
    "- 身体部位：即身体部位，例如：头，颈，胸，背，腰，腿，足。\n",
    "- 检查项目：包括检查项目，检查结果，检查结论。\n",
    "- 问诊医学概念：包括性别,年龄, 职业, 发病时间, 伴随症状，饮食情况，症状程度，曾用药，是否手术等等。\n",
    "\n",
    "现在，对于以下这个医生的提问，\n",
    "\n",
    "{}\n",
    "\n",
    "给出医生提问中的所有对象，以 MedicalAskContent 的格式给出。\n",
    "\n",
    "注意，你给出的所有内容必须出现在医生的提问中。每种对象可能不存在，也可能存在任意数目个。\n",
    "\"\"\"\n",
    "\n",
    "class MedicalAskContent(BaseModel):\n",
    "    \n",
    "    disease: list[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"医生提问中的疾病对象\"\n",
    "    )\n",
    "    symptom: list[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"医生提问中的症状对象\"\n",
    "    )\n",
    "    medcine: list[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"医生提问中的药物对象\"\n",
    "    )\n",
    "    surgery: list[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"医生提问中的手术对象\"\n",
    "    )\n",
    "    body_part: list[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"医生提问中的身体部位对象\"\n",
    "    )\n",
    "    medical_check: list[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"医生提问中的检查项目对象\"\n",
    "    )\n",
    "    concept: list[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"医生提问中的问诊医学概念对象\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = pickle.load(open(work_on_data, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rework(each):\n",
    "    if not each['response_structured_with_raw']['parsed'].is_asking:\n",
    "        each['is_asking'] = False\n",
    "        each['ask_sentence'] = \"\"\n",
    "        return\n",
    "    each['is_asking'] = True\n",
    "    res = aux_llm.with_structured_output(AskingPart).invoke(\n",
    "        prompt_ask.format(each['response_structured_with_raw']['parsed'].text)\n",
    "    )\n",
    "    each['ask_sentence'] = res.asking\n",
    "    res2 = llm.with_structured_output(MedicalAskContent).invoke(\n",
    "        prompt.format(res)\n",
    "    )\n",
    "    each['objs'] = res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(ld))):\n",
    "    rework(ld[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ld, open(work_on_data, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "# Should be the path to the output of second_pass_gen\n",
    "rendered_prompts_path = './rendered_prompts.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2TokenizerFast\n",
    "import regex\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from datasets import Dataset\n",
    "import copy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = json.load(open(rendered_prompts_path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Qwen2TokenizerFast.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_by = \"<|im_end|>\\n\"\n",
    "splitted = (formatted[0] + \"\\n\").split(splitted_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>system\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\\n{\"type\": \"function\", \"function\": {\"name\": \"RetrievalAction\", \"description\": \"The action of retrievaling from the knowledge base.\", \"parameters\": {\"properties\": {\"reasoning\": {\"description\": \"The reasong why you are doing the following query.\", \"type\": \"string\"}, \"queries\": {\"description\": \"The list of queries to execute. Each should be a question.\", \"items\": {\"type\": \"string\"}, \"type\": \"array\"}}, \"required\": [\"reasoning\", \"queries\"], \"type\": \"object\"}}}\\n{\"type\": \"function\", \"function\": {\"name\": \"AskAction\", \"description\": \"The action of asking the patient for extra information.\", \"parameters\": {\"properties\": {\"reasoning\": {\"description\": \"The reason why you are asking the following question.\", \"type\": \"string\"}, \"disease\": {\"description\": \"你提问的疾病对象\", \"items\": {\"type\": \"string\"}, \"type\": \"array\"}, \"symptom\": {\"description\": \"你提问的症状对象\", \"items\": {\"type\": \"string\"}, \"type\": \"array\"}, \"medcine\": {\"description\": \"你提问的药物对象\", \"items\": {\"type\": \"string\"}, \"type\": \"array\"}, \"surgery\": {\"description\": \"你提问的手术对象\", \"items\": {\"type\": \"string\"}, \"type\": \"array\"}, \"body_part\": {\"description\": \"你提问的身体部位对象\", \"items\": {\"type\": \"string\"}, \"type\": \"array\"}, \"medical_check\": {\"description\": \"你提问的检查项目对象\", \"items\": {\"type\": \"string\"}, \"type\": \"array\"}, \"concept\": {\"description\": \"你提问的问诊医学概念对象\", \"items\": {\"type\": \"string\"}, \"type\": \"array\"}, \"text\": {\"description\": \"The text sent to the patient.\", \"type\": \"string\"}}, \"required\": [\"reasoning\", \"text\"], \"type\": \"object\"}}}\\n{\"type\": \"function\", \"function\": {\"name\": \"TellAction\", \"description\": \"The action of telling the patient something.\", \"parameters\": {\"properties\": {\"reasoning\": {\"description\": \"The reason why you are telling the user the following text.\", \"type\": \"string\"}, \"text\": {\"description\": \"The text sent to the patient.\", \"type\": \"string\"}}, \"required\": [\"reasoning\", \"text\"], \"type\": \"object\"}}}\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\"name\": <function-name>, \"arguments\": <args-json-object>}\\n</tool_call>',\n",
       " '<|im_start|>user\\n### 指令\\n是一个医学专家级的AI助手。现在你需要根据已有信息，给出下一个Action，如果信息不足，可以使用RetrievalAction查询知识库，或使用AskAction询问患者。如果信息充足，可以使用TellAction告知患者信息。注意，你一次只能执行一个Action。\\n\\n### 医患历史对话\\n患者：面瘫。带状疱疹起在耳部，后引起面瘫，吃药后无效。\\n医生：凡此种病一般较重，定位方法治疗效果较好！\\n患者：什么叫定位治疗。\\n\\n',\n",
       " '<|im_start|>assistant\\n<tool_call>\\n{\"name\": \"RetrievalAction\", \"arguments\": {\"reasoning\": \"患者提到面瘫和带状疱疹的关系，询问无效的药物治疗和定位治疗的定义，因此需要了解面瘫的治疗方法和定位治疗的相关信息。\", \"queries\": [\"面瘫的治疗方法\", \"什么是定位治疗\"]}}\\n</tool_call>',\n",
       " '<|im_start|>user\\n<tool_response>\\n[{\"query\": \"面瘫的治疗方法\", \"refined_result\": \"面瘫可以通过药物、针灸或膏摩疗法来治疗。对于由风寒引起的症状，可以考虑使用葛根汤等中药；针灸通过刺激特定穴位调节气血平衡；膏摩则结合药膏和推拿来促进康复。重要的是要根据个人情况选择合适的治疗方法，并及时就医。\"}, {\"query\": \"什么是定位治疗\", \"refined_result\": \"定位治疗可能是指针对特定疾病或病因进行的治疗方法，旨在根治疾病。这种治疗需要根据患者的具体情况来制定，常用的方法包括药物、手术和物理治疗等。\"}]\\n</tool_response>',\n",
       " '<|im_start|>assistant\\n<tool_call>\\n{\"name\": \"TellAction\", \"arguments\": {\"reasoning\": \"医生需要解释面瘫的治疗方法和定位治疗的含义，以帮助患者理解治疗方案。\", \"text\": \"定位治疗是针对特定疾病或病因进行的治疗方法，旨在根治疾病。对于面瘫，可以通过药物、针灸或膏摩疗法来治疗。药物治疗可能包括中药和西药，针灸通过刺激特定穴位调节气血平衡，而膏摩则结合药膏和推拿来促进康复。具体的治疗方案需要根据您的个人情况来制定。\"}}\\n</tool_call>',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_one(example: str):\n",
    "    if not example.endswith(\"\\n\"):\n",
    "        example = example + \"\\n\"\n",
    "    splitted_by = \"<|im_end|>\\n\"\n",
    "    splitted = example.split(splitted_by)\n",
    "    input_ids = []\n",
    "    labels = []\n",
    "    attention_mask = []\n",
    "    ret = []\n",
    "    for idx,each in enumerate(splitted):\n",
    "        if each.startswith(\"<|im_start|>system\") or each.startswith(\"<|im_start|>user\"):\n",
    "            full = each + splitted_by\n",
    "            this_input_ids = tokenizer.encode(full)\n",
    "            labels.extend([-100] * len(tokenizer.encode(full)))\n",
    "            input_ids.extend(this_input_ids)\n",
    "            attention_mask.extend([1] * len(this_input_ids))\n",
    "            continue\n",
    "        if each.startswith(\"<|im_start|>assistant\"):\n",
    "            full = each\n",
    "            if idx != len(splitted) - 1:\n",
    "                full = each + splitted_by\n",
    "            this_input_ids = tokenizer.encode(\"\\n\" + full)\n",
    "            input_ids_cp = copy.deepcopy(input_ids)[:-1]\n",
    "            labels_cp = copy.deepcopy(labels)[:-1]\n",
    "            attention_mask_cp = copy.deepcopy(attention_mask)[:-1]\n",
    "            input_ids_cp.extend(this_input_ids)\n",
    "            labels_cp.extend(this_input_ids)\n",
    "            attention_mask_cp.extend([1] * len(this_input_ids))\n",
    "            input_ids_cp.extend([tokenizer.pad_token_id])\n",
    "            labels_cp.extend([tokenizer.pad_token_id])\n",
    "            attention_mask_cp.extend([1])\n",
    "            non_pad_len = len(input_ids_cp)\n",
    "            if non_pad_len > max_seq_len:\n",
    "                print(\"OUT OF LENGTH\")\n",
    "                continue\n",
    "            \n",
    "            ret.append({\n",
    "                \"input_ids\": input_ids_cp + [tokenizer.pad_token_id] * (max_seq_len - non_pad_len),\n",
    "                \"labels\": labels_cp + [-100] * (max_seq_len - non_pad_len),\n",
    "                \"attention_mask\": attention_mask_cp + [0] * (max_seq_len - non_pad_len),\n",
    "            })\n",
    "            \n",
    "            # ret.append({\n",
    "            #     \"input_ids\": torch.tensor(input_ids_cp + [tokenizer.pad_token_id] * (max_seq_len - non_pad_len), dtype=torch.long),\n",
    "            #     \"labels\": torch.tensor(labels_cp + [-100] * (max_seq_len - non_pad_len), dtype=torch.long),\n",
    "            #     \"attention_mask\": torch.tensor(attention_mask_cp + [0] * (max_seq_len - non_pad_len), dtype=torch.long),\n",
    "            # })\n",
    "\n",
    "            input_ids.extend(this_input_ids)\n",
    "            labels.extend([-100] * len(this_input_ids))\n",
    "            attention_mask.extend([1] * len(this_input_ids))\n",
    "            continue\n",
    "        if each == '':\n",
    "            continue\n",
    "        raise Exception(\"SHOULD NOT BE HERE\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65017/65017 [00:03<00:00, 18330.29it/s]\n",
      " 87%|████████▋ | 56386/65017 [01:10<00:10, 829.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT OF LENGTH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65017/65017 [01:39<00:00, 652.08it/s] \n"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor(max_workers=16) as executor:\n",
    "    futures = []\n",
    "    for each in tqdm(formatted):\n",
    "        futures.append(executor.submit(tokenize_one, each))\n",
    "    for future in tqdm(futures):\n",
    "        r.extend(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_list(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121d21dc09834d2bba3fc89f9ec1ce1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/9 shards):   0%|          | 0/151203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.save_to_disk(\"./train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<|im_start|>assistant\n",
      "<tool_call>\n",
      "{\"name\": \"RetrievalAction\", \"arguments\": {\"reasoning\": \"患者已经经历过冷冻治疗，但表示疼痛且影响行动，因此希望了解其他治疗方法。同时，患者提到跖疣复发且加重，询问原因有助于理解病情。\", \"queries\": [\"跖疣的其他治疗方法有哪些？\", \"跖疣复发加重的原因是什么？\"]}}\n",
      "</tool_call><|im_end|>\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(\n",
    "    [e for e in r[9]['labels'] if e != -100]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151203"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
